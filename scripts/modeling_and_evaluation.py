# -*- coding: utf-8 -*-
"""Modeling & Evaluation.ipynb"""

import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import RandomOverSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import pickle

# Charger les datasets
train_path = "data/train_clean.csv"  # Remplace par ton chemin rÃ©el
test_path = "data/test_clean.csv"    # Remplace par ton chemin rÃ©el

train_clean = pd.read_csv(train_path)
test_clean = pd.read_csv(test_path)

# 1ï¸âƒ£ Afficher les 5 premiÃ¨res lignes
print("\nðŸ”¹ AperÃ§u des 5 premiÃ¨res lignes du dataset d'entraÃ®nement (TR) :")
print(train_clean.head())

print("\nðŸ”¹ AperÃ§u des 5 premiÃ¨res lignes du dataset de test (TS) :")
print(test_clean.head())

# 2ï¸âƒ£ Obtenir les dimensions des datasets
print("\nðŸ“ Dimensions des datasets :")
print(f"Train: {train_clean.shape}, Test: {test_clean.shape}")

# 3ï¸âƒ£ Identifier les types de variables
print("\nðŸ” Types de variables dans le dataset d'entraÃ®nement (TR) :")
print(train_clean.dtypes)

print("\nðŸ” Types de variables dans le dataset de test (TS) :")
print(test_clean.dtypes)

print("\nâœ… Exploration terminÃ©e avec succÃ¨s !")

# SÃ©lectionner uniquement les colonnes numÃ©riques
numeric_columns = train_clean.select_dtypes(include=['float64', 'int64']).columns

# Calculer la matrice de corrÃ©lation sur les colonnes numÃ©riques
corr_matrix = train_clean[numeric_columns].corr()

# Identification des paires de variables avec une corrÃ©lation supÃ©rieure Ã  0.9
high_corr_var = [(i, j) for i in corr_matrix.columns for j in corr_matrix.columns if i != j and corr_matrix.loc[i, j] > 0.9]
print("Paires de variables avec une corrÃ©lation > 0.9 :")
print(high_corr_var)

# Affichage de la matrice de corrÃ©lation
print("\nMatrice de corrÃ©lation :")
print(corr_matrix)

# SÃ©lection des variables catÃ©gorielles
cat_columns = train_clean.select_dtypes(include=['object']).columns

# Test du khi-deux pour chaque paire de variables catÃ©gorielles
chi2_p_values = {}
for col1 in cat_columns:
    for col2 in cat_columns:
        if col1 != col2:
            contingency_table = pd.crosstab(train_clean[col1], train_clean[col2])
            if contingency_table.size > 0:  # Ensure the contingency table is not empty
                chi2, p, dof, expected = chi2_contingency(contingency_table)
                if p < 0.05:
                    chi2_p_values[(col1, col2)] = p
            else:
                print(f"Contingency table for {col1} and {col2} is empty, skipping chi-square test.")

# Affichage des p-values
print("\nP-values des tests du khi-deux pour les paires de variables catÃ©gorielles :")
for pair, p_value in chi2_p_values.items():
    print(f"{pair}: p-value = {p_value}")

# Gestion des valeurs manquantes pour les colonnes numÃ©riques
imputer = SimpleImputer(strategy='mean')
train_imputed = imputer.fit_transform(train_clean[numeric_columns])

# Standardisation des donnÃ©es
scaler = StandardScaler()
train_scaled = scaler.fit_transform(train_imputed)

# Application de la PCA
pca = PCA()
train_pca = pca.fit_transform(train_scaled)

# Variance expliquÃ©e par chaque composante principale
explained_variance = pca.explained_variance_ratio_

# Affichage de la variance expliquÃ©e cumulÃ©e
cumulative_variance = explained_variance.cumsum()
print("\nVariance expliquÃ©e cumulÃ©e par les composantes principales :")
print(cumulative_variance)

# Affichage de l'histogramme de la variable cible
plt.figure(figsize=(10, 6))
sns.histplot(train_clean['saleprice'], kde=True, color='blue', bins=30)
plt.title('Distribution de la variable cible : SalePrice')
plt.xlabel('saleprice')
plt.ylabel('FrÃ©quence')
plt.show()

# Encodage one-hot pour les variables catÃ©gorielles
train_clean = pd.get_dummies(train_clean, columns=cat_columns, drop_first=True)

# DÃ©finir 3 groupes : "Bas", "Moyen", "Ã‰levÃ©"
train_clean["Price_Category"] = pd.qcut(train_clean["saleprice"], q=3, labels=["Bas", "Moyen", "Ã‰levÃ©"])

# SÃ©parer X et y
X = train_clean.drop(columns=["id", "saleprice", "Price_Category"])
y = train_clean["Price_Category"]

# Appliquer le surÃ©chantillonnage
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# Afficher la nouvelle distribution aprÃ¨s surÃ©chantillonnage
plt.figure(figsize=(8, 5))
sns.countplot(x=y_resampled)
plt.title("Distribution des catÃ©gories de SalePrice aprÃ¨s surÃ©chantillonnage")
plt.xlabel("CatÃ©gorie de prix")
plt.ylabel("Nombre d'exemples")
plt.show()

# SÃ©parer les donnÃ©es en train et test (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Initialiser le modÃ¨le RandomForestClassifier
rf_model = RandomForestClassifier(random_state=42)

# EntraÃ®ner le modÃ¨le
rf_model.fit(X_train, y_train)

# Faire des prÃ©dictions sur l'ensemble de test
y_pred = rf_model.predict(X_test)

# Ã‰valuer les performances du modÃ¨le
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy du modÃ¨le Random Forest (AprÃ¨s surÃ©chantillonnage) : {accuracy:.2f}")

# Afficher un rapport de classification pour Ã©valuer les performances sur chaque catÃ©gorie
print("Classification Report :")
print(classification_report(y_test, y_pred))

# Matrice de confusion aprÃ¨s surÃ©chantillonnage
cm_after = confusion_matrix(y_test, y_pred)

# Affichage de la matrice de confusion aprÃ¨s surÃ©chantillonnage
plt.figure(figsize=(8, 6))
sns.heatmap(cm_after, annot=True, fmt="d", cmap="Blues", xticklabels=["Bas", "Moyen", "Ã‰levÃ©"], yticklabels=["Bas", "Moyen", "Ã‰levÃ©"])
plt.title("Matrice de confusion - AprÃ¨s surÃ©chantillonnage")
plt.xlabel("PrÃ©dictions")
plt.ylabel("VÃ©ritables")
plt.show()

# Comparaison avant et aprÃ¨s surÃ©chantillonnage
# SÃ©parer les donnÃ©es en train et test (80% train, 20% test) avant surÃ©chantillonnage
X_train_before, X_test_before, y_train_before, y_test_before = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialiser le modÃ¨le RandomForestClassifier
rf_model_before = RandomForestClassifier(random_state=42)

# EntraÃ®ner le modÃ¨le sur les donnÃ©es avant le surÃ©chantillonnage
rf_model_before.fit(X_train_before, y_train_before)

# Faire des prÃ©dictions sur l'ensemble de test
y_pred_before = rf_model_before.predict(X_test_before)

# Ã‰valuer les performances du modÃ¨le avant surÃ©chantillonnage
accuracy_before = accuracy_score(y_test_before, y_pred_before)
print(f"Accuracy du modÃ¨le Random Forest (avant surÃ©chantillonnage) : {accuracy_before:.2f}")

# Afficher un rapport de classification pour Ã©valuer les performances sur chaque catÃ©gorie
print("Classification Report (avant surÃ©chantillonnage) :")
print(classification_report(y_test_before, y_pred_before))

# Matrice de confusion avant surÃ©chantillonnage
cm_before = confusion_matrix(y_test_before, y_pred_before)

# Affichage de la matrice de confusion avant surÃ©chantillonnage
plt.figure(figsize=(8, 6))
sns.heatmap(cm_before, annot=True, fmt="d", cmap="Blues", xticklabels=["Bas", "Moyen", "Ã‰levÃ©"], yticklabels=["Bas", "Moyen", "Ã‰levÃ©"])
plt.title("Matrice de confusion - Avant surÃ©chantillonnage")
plt.xlabel("PrÃ©dictions")
plt.ylabel("VÃ©ritables")
plt.show()

# Save the trained model
model_path = 'model/random_forest_model.pkl'
with open(model_path, 'wb') as file:
    pickle.dump(rf_model, file)

# Evaluate the model
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)
# -*- coding: utf-8 -*-
"""Modeling & Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aLCTLDqBQ8a_iEQYDiXLieRa34Vc4Skz
"""

import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

import pandas as pd

# Charger les datasets
train_path = "data/train_clean.csv"  # Remplace par ton chemin r√©el
test_path = "data/test_clean.csv"    # Remplace par ton chemin r√©el

train_clean = pd.read_csv(train_path)
test__clean = pd.read_csv(test_path)

# 1Ô∏è‚É£ Afficher les 5 premi√®res lignes
print("\nüîπ Aper√ßu des 5 premi√®res lignes du dataset d'entra√Ænement (TR) :")
print(train_clean.head())

print("\nüîπ Aper√ßu des 5 premi√®res lignes du dataset de test (TS) :")
print(test__clean.head())

# 2Ô∏è‚É£ Obtenir les dimensions des datasets
print("\nüìè Dimensions des datasets :")
print(f"data/train: {train_clean.shape}, Test: {test__clean.shape}")

# 3Ô∏è‚É£ Identifier les types de variables
print("\nüîç Types de variables dans le dataset d'entra√Ænement (TR) :")
print(train_clean.dtypes)

print("\nüîç Types de variables dans le dataset de test (TS) :")
print(test__clean.dtypes)

print("\n‚úÖ Exploration termin√©e avec succ√®s !")

# S√©lectionner uniquement les colonnes num√©riques
numeric_columns = train_clean.select_dtypes(include=['float64', 'int64']).columns

# Calculer la matrice de corr√©lation sur les colonnes num√©riques
corr_matrix = train_clean[numeric_columns].corr()

# Identification des paires de variables avec une corr√©lation sup√©rieure √† 0.9
high_corr_var = [(i, j) for i in corr_matrix.columns for j in corr_matrix.columns if i != j and corr_matrix.loc[i, j] > 0.9]
print(high_corr_var)

# S√©lectionner uniquement les colonnes num√©riques
numeric_columns = train_clean.select_dtypes(include=['float64', 'int64']).columns

# Calculer la matrice de corr√©lation sur les colonnes num√©riques
corr_matrix = train_clean[numeric_columns].corr()

# Affichage de la matrice de corr√©lation
print(corr_matrix)

import pandas as pd
from scipy.stats import chi2_contingency

# S√©lection des variables cat√©gorielles
cat_columns = train_clean.select_dtypes(include=['object']).columns

# Test du khi-deux pour chaque paire de variables cat√©gorielles
for col1 in cat_columns:
    for col2 in cat_columns:
        if col1 != col2:
            contingency_table = pd.crosstab(train_clean[col1], train_clean[col2])
            chi2, p, dof, expected = chi2_contingency(contingency_table)
            if p < 0.05:
                print(f"Les variables {col1} et {col2} sont significativement corr√©l√©es (p-value = {p})")

import pandas as pd
from scipy.stats import chi2_contingency

# S√©lection des variables cat√©gorielles
cat_columns = train_clean.select_dtypes(include=['object']).columns

# Dictionnaire pour stocker les p-values des tests du khi-deux
chi2_p_values = {}

# Test du khi-deux pour chaque paire de variables cat√©gorielles
for col1 in cat_columns:
    for col2 in cat_columns:
        if col1 != col2:
            contingency_table = pd.crosstab(train_clean[col1], train_clean[col2])
            chi2, p, dof, expected = chi2_contingency(contingency_table)
            if p < 0.05:
                chi2_p_values[(col1, col2)] = p

# Affichage des p-values
print("P-values des tests du khi-deux pour les paires de variables cat√©gorielles :")
for pair, p_value in chi2_p_values.items():
    print(f"{pair}: p-value = {p_value}")

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# S√©lection des variables num√©riques
num_columns = train_clean.select_dtypes(include=['float64', 'int64']).columns

# Standardisation des donn√©es
scaler = StandardScaler()
train_scaled = scaler.fit_transform(train_clean[num_columns])

# Application de la PCA
pca = PCA()
train_pca = pca.fit_transform(train_scaled)

# Variance expliqu√©e par chaque composante principale
explained_variance = pca.explained_variance_ratio_

# Affichage de la variance expliqu√©e cumul√©e
cumulative_variance = explained_variance.cumsum()
print("Variance expliqu√©e cumul√©e par les composantes principales :")
print(cumulative_variance)

import matplotlib.pyplot as plt
import seaborn as sns

# Affichage de l'histogramme de la variable cible
plt.figure(figsize=(10, 6))
sns.histplot(train_clean['saleprice'], kde=True, color='blue', bins=30)
plt.title('Distribution de la variable cible : SalePrice')
plt.xlabel('saleprice')
plt.ylabel('Fr√©quence')
plt.show()

import matplotlib.pyplot as plt

# Affichage de l'histogramme de la variable cible
train_clean['saleprice'].plot(kind='hist', bins=50, edgecolor='black')
plt.title('Distribution de saleprice')
plt.xlabel('saleprice')
plt.ylabel('Fr√©quence')
plt.show()

print(train_clean.dtypes)

# Identification des colonnes de type 'object'
colonnes_categorielles = train_clean.select_dtypes(include=['object']).columns
print("Colonnes cat√©gorielles :", colonnes_categorielles)

# Encodage one-hot pour les variables cat√©gorielles
train_clean = pd.get_dummies(train_clean, columns=colonnes_categorielles, drop_first=True)

print(train_clean.dtypes)

colonnes_non_numeriques = train_clean.select_dtypes(include=['object']).columns
print("Colonnes non num√©riques :", colonnes_non_numeriques)

import matplotlib.pyplot as plt
import seaborn as sns

# Afficher la distribution de la variable cible 'saleprice'
plt.figure(figsize=(10,6))
sns.histplot(train_clean['saleprice'], kde=True)
plt.title('Distribution de saleprice')
plt.xlabel('Saleprice')
plt.ylabel('Fr√©quence')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler

# D√©finir 3 groupes : "Bas", "Moyen", "√âlev√©"
train_clean["Price_Category"] = pd.qcut(train_clean["saleprice"], q=3, labels=["Bas", "Moyen", "√âlev√©"])

# S√©parer X et y
X = train_clean.drop(columns=["id", "saleprice", "Price_Category"])
y = train_clean["Price_Category"]

# Appliquer le sur√©chantillonnage
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# Afficher la nouvelle distribution apr√®s sur√©chantillonnage
plt.figure(figsize=(8,5))
sns.countplot(x=y_resampled)
plt.title("Distribution des cat√©gories de SalePrice apr√®s sur√©chantillonnage")
plt.xlabel("Cat√©gorie de prix")
plt.ylabel("Nombre d'exemples")
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# S√©parer les donn√©es en train et test (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Initialiser le mod√®le RandomForestClassifier
rf_model = RandomForestClassifier(random_state=42)

# Entra√Æner le mod√®le
rf_model.fit(X_train, y_train)

# Faire des pr√©dictions sur l'ensemble de test
y_pred = rf_model.predict(X_test)

# √âvaluer les performances du mod√®le
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy du mod√®le Random Forest (Apr√®s sur√©chantillonnage ) : {accuracy:.2f}")

# Afficher un rapport de classification pour √©valuer les performances sur chaque cat√©gorie
print("Classification Report :")
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# S√©parer les donn√©es en train et test (80% train, 20% test)
X = train_clean.drop(columns=["id", "saleprice", "Price_Category"])  # Les features
y = train_clean["Price_Category"]  # La cible

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialiser le mod√®le RandomForestClassifier
rf_model_before_resampling = RandomForestClassifier(random_state=42)

# Entra√Æner le mod√®le sur les donn√©es avant le sur√©chantillonnage
rf_model_before_resampling.fit(X_train, y_train)

# Faire des pr√©dictions sur l'ensemble de test
y_pred_before = rf_model_before_resampling.predict(X_test)

# √âvaluer les performances du mod√®le
accuracy_before = accuracy_score(y_test, y_pred_before)
print(f"Accuracy du mod√®le Random Forest (avant sur√©chantillonnage) : {accuracy_before:.2f}")

# Afficher un rapport de classification pour √©valuer les performances sur chaque cat√©gorie
print("Classification Report (avant sur√©chantillonnage) :")
print(classification_report(y_test, y_pred_before))

y_pred_before = rf_model_before_resampling.predict(X_test)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Matrice de confusion avant sur√©chantillonnage
cm_before = confusion_matrix(y_test, y_pred_before)

# Affichage de la matrice de confusion avant sur√©chantillonnage
plt.figure(figsize=(8, 6))
sns.heatmap(cm_before, annot=True, fmt="d", cmap="Blues", xticklabels=["Bas", "Moyen", "√âlev√©"], yticklabels=["Bas", "Moyen", "√âlev√©"])
plt.title("Matrice de confusion - Avant sur√©chantillonnage")
plt.xlabel("Pr√©dictions")
plt.ylabel("V√©ritables")
plt.show()

# Matrice de confusion apr√®s sur√©chantillonnage
cm_after = confusion_matrix(y_test, y_pred)

# Affichage de la matrice de confusion apr√®s sur√©chantillonnage
plt.figure(figsize=(8, 6))
sns.heatmap(cm_after, annot=True, fmt="d", cmap="Blues", xticklabels=["Bas", "Moyen", "√âlev√©"], yticklabels=["Bas", "Moyen", "√âlev√©"])
plt.title("Matrice de confusion - Apr√®s sur√©chantillonnage")
plt.xlabel("Pr√©dictions")
plt.ylabel("V√©ritables")
plt.show()

# Pour le mod√®le avant sur√©chantillonnage
print(f"Accuracy avant sur√©chantillonnage : {accuracy_before:.2f}")
print("Rapport de classification avant sur√©chantillonnage :")
print(classification_report(y_test, y_pred_before))

# Pour le mod√®le apr√®s sur√©chantillonnage
accuracy_after = accuracy_score(y_test, y_pred)
print(f"Accuracy apr√®s sur√©chantillonnage : {accuracy_after:.2f}")
print("Rapport de classification apr√®s sur√©chantillonnage :")
print(classification_report(y_test, y_pred))

"""Avant sur√©chantillonnage :
Accuracy : 90%
Classe "Bas" : Recall 95%, F1-score 91%
Classe "Moyen" : Recall 83%, F1-score 87%
Classe "√âlev√©" : Recall 95%, F1-score 94%
Observation : Le mod√®le semble bien fonctionner, mais il favorise peut-√™tre les classes majoritaires.

Apr√®s sur√©chantillonnage :
Accuracy : 81% (baisse de 9%)
Classe "Bas" : Recall 91% (+4%), F1-score 83%
Classe "Moyen" : Recall 66% (-17%), F1-score 73%
Classe "√âlev√©" : Recall 89% (-6%), F1-score 88%
Observation :
Le mod√®le est plus √©quilibr√© entre les classes.
Il est meilleur pour la classe "Bas" (meilleur recall).
Il a plus de difficult√© avec la classe "Moyen" (baisse du recall).
"""

